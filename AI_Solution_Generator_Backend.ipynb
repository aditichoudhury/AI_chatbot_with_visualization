{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2tZdjEoHQibNQmblp4HWJcekzQQ_5uGUp55CAug9pe12oK3M3"
      ],
      "metadata": {
        "id": "hw_790lP9pJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a7503c-300c-4c51-cb92-8534fc9b50bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /usr/local/bin/ngrok /content/drive/MyDrive/\n",
        "!cp /content/drive/MyDrive/ngrok /usr/local/bin/\n",
        "!ngrok authtoken 2tZdjEoHQibNQmblp4HWJcekzQQ_5uGUp55CAug9pe12oK3M3\n"
      ],
      "metadata": {
        "id": "Yz-PKhrI_E2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb7e8cb-3355-4284-d5a4-3c9e3cc0bdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Auto-install required packages\n",
        "!pip install -q fastapi uvicorn transformers torch nest_asyncio pyngrok\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "print(\"✅ All packages installed and ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWzTjLYhghJE",
        "outputId": "8af02a68-c62e-41da-800d-75a705f832a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ All packages installed and ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "\n",
        "# ✅ Apply nest_asyncio to prevent asyncio errors\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ✅ Initialize Gemini API client\n",
        "client = genai.Client(api_key=\"AIzaSyDXAXddYj8wDxIlO_ut7xqsQYWgj_NQdks\")\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# ✅ Enable CORS for frontend communication\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # Allow all origins for now, restrict in production\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class GeminiRequest(BaseModel):\n",
        "    query: str\n",
        "\n",
        "@app.post(\"/gemini\")\n",
        "async def generate_gemini_response(request: GeminiRequest):\n",
        "    \"\"\"Generate content using Gemini API.\"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=request.query,\n",
        "        )\n",
        "        return {\"response\": response.text}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# ✅ Close any existing Ngrok tunnels before creating a new one\n",
        "try:\n",
        "    ngrok.kill()  # Ensure all old tunnels are closed\n",
        "    ngrok_tunnel = ngrok.connect(8000)\n",
        "    print(f\"🚀 Public URL: {ngrok_tunnel.public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Ngrok Error: {str(e)}\")\n",
        "\n",
        "# ✅ Run Uvicorn without asyncio conflicts\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30QgAj9byhYZ",
        "outputId": "9c632c88-8d6e-4b3b-a6ca-dafdb87d11fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [21666]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Public URL: https://5fc9-34-142-213-181.ngrok-free.app\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"OPTIONS /generate HTTP/1.1\" 200 OK\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST /generate HTTP/1.1\" 404 Not Found\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST /generate HTTP/1.1\" 404 Not Found\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"OPTIONS / HTTP/1.1\" 200 OK\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"OPTIONS /gemini HTTP/1.1\" 200 OK\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST /gemini HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST /gemini HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST /gemini HTTP/1.1\" 200 OK\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST /gemini HTTP/1.1\" 200 OK\n",
            "INFO:     2401:4900:8fd3:37cc:a86d:a27c:5852:2a80:0 - \"POST /gemini HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}